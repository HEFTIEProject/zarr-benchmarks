{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_benchmarks_json(path_to_file: str) -> dict:\n",
    "    with open(path_to_file, \"r\") as in_file_obj:\n",
    "        text = in_file_obj.read()\n",
    "        # convert the text into a dictionary\n",
    "        return json.loads(text)\n",
    "\n",
    "\n",
    "def prepare_benchmarks_dataframe(json_dict: dict) -> pd.DataFrame:\n",
    "    benchmark_df = pd.json_normalize(json_dict[\"benchmarks\"])\n",
    "\n",
    "    # copy compression ratio from read benchmarks to write benchmarks\n",
    "    param_cols = [col for col in benchmark_df if col.startswith(\"params\")]\n",
    "    benchmark_df[\"compression_ratio\"] = benchmark_df.groupby(\n",
    "        param_cols, dropna=False, as_index=False\n",
    "    )[\"extra_info.compression_ratio\"].transform(\"max\")\n",
    "\n",
    "    # combine compression level columns for different compressors\n",
    "    benchmark_df[\"compression_level\"] = benchmark_df[\n",
    "        [\"params.blosc_clevel\", \"params.gzip_level\", \"params.zstd_level\"]\n",
    "    ].max(axis=1)\n",
    "\n",
    "    # create column for type of compressor\n",
    "    benchmark_df[\"compressor\"] = \"\"\n",
    "    blosc_compressors = (\n",
    "        \"blosc-\"\n",
    "        + benchmark_df.loc[\n",
    "            ~benchmark_df[\"params.blosc_clevel\"].isna(), \"params.blosc_cname\"\n",
    "        ]\n",
    "    )\n",
    "    benchmark_df.loc[~benchmark_df[\"params.blosc_clevel\"].isna(), \"compressor\"] = (\n",
    "        blosc_compressors\n",
    "    )\n",
    "    benchmark_df.loc[~benchmark_df[\"params.gzip_level\"].isna(), \"compressor\"] = \"gzip\"\n",
    "    benchmark_df.loc[~benchmark_df[\"params.zstd_level\"].isna(), \"compressor\"] = \"zstd\"\n",
    "\n",
    "    # remove un-needed columns\n",
    "    stats_cols = [col for col in benchmark_df if col.startswith(\"stats\")]\n",
    "    benchmark_df = benchmark_df[\n",
    "        [\n",
    "            \"group\",\n",
    "            \"compressor\",\n",
    "            \"compression_level\",\n",
    "            \"compression_ratio\",\n",
    "            \"params.chunk_size\",\n",
    "        ]\n",
    "        + stats_cols\n",
    "    ]\n",
    "    benchmark_df = benchmark_df.rename(columns={\"params.chunk_size\": \"chunk_size\"})\n",
    "\n",
    "    return benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"../data/json/0007_zarr-python-v2.json\"\n",
    "json_dict = load_benchmarks_json(json_path)\n",
    "benchmark_df = prepare_benchmarks_dataframe(json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_benchmarks = benchmark_df[benchmark_df.group == \"write\"]\n",
    "read_benchmarks = benchmark_df[benchmark_df.group == \"read\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_benchmarks_chunks_200 = write_benchmarks[write_benchmarks.chunk_size == 200]\n",
    "read_benchmarks_chunks_200 = read_benchmarks[read_benchmarks.chunk_size == 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As compression ratio increases, so does mean write time\n",
    "graph = sns.relplot(\n",
    "    data=write_benchmarks_chunks_200,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean write time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read time doesn't vary greatly depending on compression ratio; but does vary significantly between compressors\n",
    "graph = sns.relplot(\n",
    "    data=read_benchmarks_chunks_200,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher compression level = higher compression ratio\n",
    "graph = sns.relplot(\n",
    "    data=write_benchmarks_chunks_200,\n",
    "    x=\"compression_level\",\n",
    "    y=\"compression_ratio\",\n",
    "    col=\"compressor\",\n",
    "    hue=\"compressor\",\n",
    "    facet_kws=dict(sharex=False),\n",
    ")\n",
    "graph.set_axis_labels(\"Compression level\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher compression ratio = larger write time\n",
    "graph = sns.relplot(\n",
    "    data=write_benchmarks_chunks_200,\n",
    "    x=\"compression_level\",\n",
    "    y=\"stats.mean\",\n",
    "    col=\"compressor\",\n",
    "    hue=\"compressor\",\n",
    "    facet_kws=dict(sharex=False, sharey=False),\n",
    ")\n",
    "graph.set_axis_labels(\"Compression level\", \"Mean write time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher compression level, doesn't always mean higher read time (but maybe for some compressors? Would need more points...)\n",
    "graph = sns.relplot(\n",
    "    data=read_benchmarks_chunks_200,\n",
    "    x=\"compression_level\",\n",
    "    y=\"stats.mean\",\n",
    "    col=\"compressor\",\n",
    "    hue=\"compressor\",\n",
    "    facet_kws=dict(sharex=False, sharey=False),\n",
    ")\n",
    "graph.set_axis_labels(\"Compression level\", \"Mean read time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher write time for higher compression ratios (regardless of chunk size)\n",
    "graph = sns.relplot(\n",
    "    data=write_benchmarks,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    col=\"chunk_size\",\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean write time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sns.relplot(\n",
    "    data=read_benchmarks,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    col=\"chunk_size\",\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping compression level the same, larger chunks sizes compress worse\n",
    "for compressor in benchmark_df.compressor.unique():\n",
    "    compressor_reads = read_benchmarks[read_benchmarks.compressor == compressor]\n",
    "    graph = sns.relplot(\n",
    "        data=compressor_reads,\n",
    "        x=\"chunk_size\",\n",
    "        y=\"compression_ratio\",\n",
    "        hue=\"compressor\",\n",
    "        style=\"compressor\",\n",
    "        col=\"compression_level\",\n",
    "        height=4,\n",
    "        aspect=1.2,\n",
    "    )\n",
    "    graph.set_axis_labels(\"Chunk size\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
