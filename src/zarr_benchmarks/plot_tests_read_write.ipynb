{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from zarr_benchmarks.parse_json_for_plots import get_benchmarks_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "package_paths_dict = {\n",
    "    \"zarr_python_2\": \"../../example_results/0001_zarr-python-v2.json\",\n",
    "    \"zarr_python_3\": \"../../example_results/0002_zarr-python-v3.json\",\n",
    "    \"tensorstore\": \"../../example_results/0003_tensorstore.json\",\n",
    "}\n",
    "benchmarks_df = get_benchmarks_dataframe(package_paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_write_benchmarks = benchmarks_df[\n",
    "    benchmarks_df.chunk_size.isin([64, 128])\n",
    "    & (~benchmarks_df.blosc_shuffle.isin([\"bitshuffle\", \"noshuffle\"]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_write_benchmarks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Zarr-python v2 (read-write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_zarr_v2 = read_write_benchmarks[\n",
    "    read_write_benchmarks.package == \"zarr_python_2\"\n",
    "]\n",
    "write_zarr_v2 = benchmarks_zarr_v2[benchmarks_zarr_v2.group == \"write\"]\n",
    "read_zarr_v2 = benchmarks_zarr_v2[benchmarks_zarr_v2.group == \"read\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_zarr_v2_chunks_128 = write_zarr_v2[write_zarr_v2.chunk_size == 128]\n",
    "read_zarr_v2_chunks_128 = read_zarr_v2[read_zarr_v2.chunk_size == 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As compression ratio increases, so does mean write time\n",
    "graph = sns.relplot(\n",
    "    data=write_zarr_v2_chunks_128,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean write time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As compression ratio increases, so does mean write time (LOG SCALE)\n",
    "graph = sns.relplot(\n",
    "    data=write_zarr_v2_chunks_128,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    ")\n",
    "graph.set(xscale=\"log\")\n",
    "graph.set_axis_labels(\"Mean write time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blosc only with xlim to see left\n",
    "blosc_only_write = write_zarr_v2_chunks_128[\n",
    "    ~write_zarr_v2_chunks_128.compressor.isin([\"gzip\", \"zstd\"])\n",
    "]\n",
    "graph = sns.relplot(\n",
    "    data=blosc_only_write,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    "    facet_kws=dict(xlim=(0, 5)),\n",
    ")\n",
    "graph.set_axis_labels(\"Mean write time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read time doesn't vary greatly depending on compression ratio; but does vary significantly between compressors\n",
    "graph = sns.relplot(\n",
    "    data=read_zarr_v2_chunks_128,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read time doesn't vary greatly depending on compression ratio; but does vary significantly between compressors\n",
    "graph = sns.relplot(\n",
    "    data=read_zarr_v2_chunks_128,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    ")\n",
    "graph.set(xscale=\"log\")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read time doesn't vary greatly depending on compression ratio; but does vary significantly between compressors\n",
    "\n",
    "df = read_zarr_v2_chunks_128\n",
    "read_zarr_v2_chunks_128 = read_zarr_v2_chunks_128.explode(column=\"stats.data\")\n",
    "\n",
    "graph = sns.relplot(\n",
    "    data=read_zarr_v2_chunks_128,\n",
    "    x=\"stats.data\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    kind=\"line\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    ")\n",
    "graph.set(xscale=\"log\")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read time doesn't vary greatly depending on compression ratio; but does vary significantly between compressors\n",
    "\n",
    "read_zarr_v2_chunks_128 = read_zarr_v2[read_zarr_v2.chunk_size == 128]\n",
    "\n",
    "df = read_zarr_v2_chunks_128\n",
    "df = df.reset_index()\n",
    "df = df.explode(column=\"stats.data\")\n",
    "# df = df.melt(id_vars=[\"stats.mean\", \"compression_ratio\"], value_vars=[\"stats.data\"], var_name=\"measurement_number\", value_name=\"measured_value\")\n",
    "# graph = sns.relplot(\n",
    "#     data=read_zarr_v2_chunks_128,\n",
    "#     x=\"stats.data\",\n",
    "#     y=\"compression_ratio\",\n",
    "#     hue=\"compressor\",\n",
    "#     style=\"compressor\",\n",
    "#     size=\"compression_level\",\n",
    "#     kind=\"line\",\n",
    "#     height=4,\n",
    "#     aspect=1.5,\n",
    "# )\n",
    "# graph.set(xscale=\"log\")\n",
    "# graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")\n",
    "sns.relplot(x=\"stats.data\", y=\"compression_ratio\", kind=\"line\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# example data\n",
    "# x = np.array([0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0])\n",
    "# y = np.exp(-x)\n",
    "read_zarr_v2_chunks_128 = read_zarr_v2[read_zarr_v2.chunk_size == 128]\n",
    "\n",
    "df = read_zarr_v2_chunks_128\n",
    "# x_llim = df[\"stats.mean\"] - 2*df[\"stats.stddev\"]\n",
    "# x_ulim = df[\"stats.mean\"] + 2*df[\"stats.stddev\"]\n",
    "x = df[\"stats.mean\"]\n",
    "y = df[\"compression_ratio\"]\n",
    "\n",
    "xerr_lower = x - df[\"stats.min\"]\n",
    "xerr_upper = df[\"stats.max\"] - x\n",
    "xerr = np.array([xerr_lower, xerr_upper])\n",
    "print(\"xerr lower:\", xerr[0])\n",
    "print(\"xerr upper:\", xerr[1])\n",
    "# x_llim = df[\"stats.min\"]\n",
    "# x_ulim = df[\"stats.max\"]\n",
    "# xerr = np.array([x_llim, x_ulim])\n",
    "\n",
    "# df = df.explode(column=\"stats.data\")\n",
    "# lower & upper limits of the error\n",
    "# x = df[\"stats.mean\"]\n",
    "# y = df[\"compression_ratio\"]\n",
    "# lolims  = df[\"stats.mean\"] - 2*df[\"stats.stddev\"]\n",
    "# uplims  = df[\"stats.mean\"] + 2*df[\"stats.stddev\"]\n",
    "# lolims = np.array([0, 0, 1, 0, 1, 0, 0, 0, 1, 0], dtype=bool)\n",
    "# uplims = np.array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1], dtype=bool)\n",
    "ls = \"dotted\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "# standard error bars\n",
    "ax.errorbar(x, y, xerr=xerr, fmt=\"o\", markersize=2)\n",
    "# ax.errorbar(x, y, fmt='o')\n",
    "\n",
    "# # including upper limits\n",
    "# ax.errorbar(x, y + 0.5, xerr=xerr, yerr=yerr, uplims=uplims,\n",
    "#             linestyle=ls)\n",
    "\n",
    "# # including lower limits\n",
    "# ax.errorbar(x, y + 1.0, xerr=xerr, yerr=yerr, lolims=lolims,\n",
    "#             linestyle=ls)\n",
    "\n",
    "# including upper and lower limits\n",
    "# ax.errorbar(x, y + 1.5, xerr=xerr, yerr=yerr,\n",
    "#             lolims=lolims, uplims=uplims,\n",
    "#             marker='o', markersize=8,\n",
    "#             linestyle=ls)\n",
    "\n",
    "# Plot a series with lower and upper limits in both x & y\n",
    "# constant x-error with varying y-error\n",
    "# xerr = 0.2\n",
    "# yerr = np.full_like(x, 0.2)\n",
    "# yerr[[3, 6]] = 0.3\n",
    "\n",
    "# # mock up some limits by modifying previous data\n",
    "# xlolims = lolims\n",
    "# xuplims = uplims\n",
    "# lolims = np.zeros_like(x)\n",
    "# uplims = np.zeros_like(x)\n",
    "# lolims[[6]] = True  # only limited at this index\n",
    "# uplims[[3]] = True  # only limited at this index\n",
    "\n",
    "# do the plotting\n",
    "# ax.errorbar(x, y + 2.1, xerr=xerr, yerr=yerr,\n",
    "#             xlolims=xlolims, xuplims=xuplims,\n",
    "#             uplims=uplims, lolims=lolims,\n",
    "#             marker='o', markersize=8,\n",
    "#             linestyle='none')\n",
    "\n",
    "# lvls = df.compression_ratio.unique()\n",
    "# for i in lvls:\n",
    "#     ax.errorbar(x = df[df['compression_ratio']==i][\"stats.mean\"],\n",
    "#                 y = df[df['compression_ratio']==i][\"compression_ratio\"],\n",
    "#                 xerr=df[df['compression_ratio']==i][\"stats.stddev\"],\n",
    "#     )\n",
    "\n",
    "# tidy up the figure\n",
    "# ax.set_xlim((0, 5.5))\n",
    "ax.set_title(\"Errorbar upper and lower limits\")\n",
    "ax.set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "read_zarr_v2_chunks_128 = read_zarr_v2[read_zarr_v2.chunk_size == 128]\n",
    "\n",
    "df = read_zarr_v2_chunks_128\n",
    "x = df[\"stats.mean\"]\n",
    "y = df[\"compression_ratio\"]\n",
    "\n",
    "# xerr_lower = x - df[\"stats.min\"]\n",
    "# xerr_upper = df[\"stats.max\"] - x\n",
    "xerr_lower = 2 * df[\"stats.stddev\"]\n",
    "xerr_upper = 2 * df[\"stats.stddev\"]\n",
    "xerr = np.array([xerr_lower, xerr_upper])\n",
    "# print(\"xerr lower:\", xerr[0])\n",
    "# print(\"xerr upper:\", xerr[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "# standard error bars\n",
    "ax.errorbar(x, y, xerr=xerr, fmt=\"o\", markersize=2)\n",
    "\n",
    "# tidy up the figure\n",
    "# ax.set_xlim((2.3, 2.8))\n",
    "ax.set_title(\"Errorbar upper and lower limits\")\n",
    "# ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_zarr_v2_chunks_128 = read_zarr_v2[read_zarr_v2.chunk_size == 128]\n",
    "\n",
    "data = read_zarr_v2_chunks_128\n",
    "x_axis = \"stats.mean\"\n",
    "y_axis = \"compression_ratio\"\n",
    "col = \"compressor\"\n",
    "plot_name = \"read_zarr_v2_chunks_128\"\n",
    "# hue = None\n",
    "# size = None\n",
    "hue = \"compressor\"\n",
    "size = \"compression_level\"\n",
    "title = None\n",
    "# hue = \"compressor\"\n",
    "# size = \"compression_level\"\n",
    "\n",
    "# plot_relplot_benchmarks(\n",
    "#         read_chunks_128,\n",
    "#         x_axis=\"stats.mean\",\n",
    "#         y_axis=\"compression_ratio\",\n",
    "#         col=\"compressor\",\n",
    "#         sub_dir_name=\"read\",\n",
    "#         plot_name=f\"{package}_chunk_size128\",\n",
    "#     )\n",
    "\n",
    "if col is None:\n",
    "    facet_kws = None\n",
    "    col_wrap = None\n",
    "    plot_name = plot_name\n",
    "else:\n",
    "    facet_kws = dict(sharex=False, sharey=False)\n",
    "    if len(data[col].unique()) < 3:\n",
    "        col_wrap = 2\n",
    "    else:\n",
    "        col_wrap = 3\n",
    "    plot_name = plot_name + \"_subplots\"\n",
    "\n",
    "# custom_palette = {\n",
    "#     \"zarr_python_2\": \"blue\",\n",
    "#     \"zarr_python_3\": \"green\",\n",
    "#     \"tensorstore\": \"orange\",\n",
    "# }\n",
    "\n",
    "compressors = data[col].unique()\n",
    "custom_palette = dict(\n",
    "    zip(compressors, sns.color_palette(\"tab10\", n_colors=len(compressors)))\n",
    ")\n",
    "\n",
    "graph = sns.relplot(\n",
    "    data=data,\n",
    "    x=x_axis,\n",
    "    y=y_axis,\n",
    "    hue=hue,\n",
    "    # style=hue,\n",
    "    size=size,\n",
    "    col=col,\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    "    facet_kws=facet_kws,\n",
    "    col_wrap=col_wrap,\n",
    ")\n",
    "\n",
    "\n",
    "# Add error bars using matplotlib\n",
    "def add_error_bars(x, y, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    xerr_lower = 2 * data[\"stats.stddev\"]\n",
    "    xerr_upper = 2 * data[\"stats.stddev\"]\n",
    "    xerr = np.array([xerr_lower, xerr_upper])\n",
    "    xerr = xerr[:, : len(x)]\n",
    "    ax.errorbar(x, y, xerr=xerr, fmt=\"o\", markersize=0.5, **kwargs)\n",
    "\n",
    "\n",
    "# Function to set x-axis limits for each subplot\n",
    "def set_x_limits(*args, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    compressor = kwargs.get(\"col_val\")  # Get the column value (e.g., compressor)\n",
    "    if compressor == \"blosc-zstd\":\n",
    "        # x_min = min(data[data.compressor == \"blosc-zstd\"][\"stats.min\"])\n",
    "        # x_max = max(data[data.compressor == \"blosc-zstd\"][\"stats.max\"])\n",
    "\n",
    "        ax.set_xlim(0, 5)  # Example limits for \"blosc-zstd\"\n",
    "    elif compressor == \"gzip\":\n",
    "        ax.set_xlim(0, 10)  # Example limits for \"gzip\"\n",
    "    else:\n",
    "        ax.set_xlim(0, 15)  # Default limits\n",
    "\n",
    "\n",
    "graph.map(add_error_bars, x_axis, y_axis)\n",
    "# graph.map(set_x_limits)\n",
    "\n",
    "range = []\n",
    "limits = []\n",
    "for compressor, ax in graph.axes_dict.items():\n",
    "    # Get the min and max values for the x-axis limits and calculate the range\n",
    "    x_min = min(data[data.compressor == compressor][\"stats.min\"])\n",
    "    x_max = max(data[data.compressor == compressor][\"stats.max\"])\n",
    "    # ax.set_xlim(x_min - 0.1*x_min, x_max + 0.1*x_max)\n",
    "    range.append(x_max - x_min)\n",
    "    limits.append((x_min, x_max))\n",
    "\n",
    "# Ensure equal aspect ratio\n",
    "# ax.set_aspect(aspect='auto', adjustable='datalim')\n",
    "\n",
    "\n",
    "max_range = max(range)\n",
    "# np.round(max_range + max_range*0.5,1)\n",
    "\n",
    "for compressor, ax in graph.axes_dict.items():\n",
    "    # Set the x-axis limits for each subplot\n",
    "    x_min = min(data[data.compressor == compressor][\"stats.min\"])\n",
    "    x_max = max(data[data.compressor == compressor][\"stats.max\"])\n",
    "    if x_max - x_min == max_range:\n",
    "        central_value = (x_min + x_max) / 2\n",
    "        # print(\"central_value:\", central_value)\n",
    "        # print(\"org_xmin:\", central_value - max_range / 2)\n",
    "        # print(\"org_xmax:\", central_value + max_range / 2)\n",
    "        x_lim_min = central_value - max_range / 2 - round(max_range, 1) / 10\n",
    "        x_lim_max = central_value + max_range / 2 + round(max_range, 1) / 10\n",
    "        ax.set_xlim(x_lim_min, x_lim_max)\n",
    "        print(\"final max_range:\", x_lim_max - x_lim_min)\n",
    "        print(\"final x_min:\", x_lim_min)\n",
    "        print(\"final x_max:\", x_lim_max)\n",
    "    else:\n",
    "        central_value = (x_min + x_max) / 2\n",
    "        x_lim_min = central_value - max_range / 2 - round(max_range, 1) / 10\n",
    "        x_lim_max = central_value + max_range / 2 + round(max_range, 1) / 10\n",
    "        ax.set_xlim(x_lim_min, x_lim_max)\n",
    "        print(\"range:\", x_lim_max - x_lim_min)\n",
    "        print(\"x_min:\", x_lim_min)\n",
    "        print(\"x_max:\", x_lim_max)\n",
    "\n",
    "# x_axis_label, y_axis_label = get_axis_labels(data, x_axis=x_axis, y_axis=y_axis)\n",
    "# graph.set_axis_labels(x_axis_label, y_axis_label)\n",
    "\n",
    "if title is not None:\n",
    "    graph.figure.suptitle(title)\n",
    "    graph.tight_layout()\n",
    "\n",
    "# ax.set_xlim((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace sns.relplot with sns.lineplot for 95% CI\n",
    "import seaborn as sns\n",
    "\n",
    "# Example for plotting with 95% CI\n",
    "graph = sns.lineplot(\n",
    "    data=read_zarr_v2_chunks_128,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    errorbar=(\"ci\", 95),  # 95% confidence interval\n",
    ")\n",
    "graph.set(xscale=\"log\")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blosc only reads\n",
    "blosc_only_read = read_zarr_v2_chunks_128[\n",
    "    ~read_zarr_v2_chunks_128.compressor.isin([\"gzip\", \"zstd\"])\n",
    "]\n",
    "graph = sns.relplot(\n",
    "    data=blosc_only_read,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    height=4,\n",
    "    aspect=1.5,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher compression level = higher compression ratio\n",
    "graph = sns.relplot(\n",
    "    data=write_zarr_v2_chunks_128,\n",
    "    x=\"compression_level\",\n",
    "    y=\"compression_ratio\",\n",
    "    col=\"compressor\",\n",
    "    hue=\"compressor\",\n",
    "    facet_kws=dict(sharex=False),\n",
    "    col_wrap=3,\n",
    ")\n",
    "graph.set_axis_labels(\"Compression level\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher compression ratio = larger write time\n",
    "graph = sns.relplot(\n",
    "    data=write_zarr_v2_chunks_128,\n",
    "    x=\"compression_level\",\n",
    "    y=\"stats.mean\",\n",
    "    col=\"compressor\",\n",
    "    hue=\"compressor\",\n",
    "    facet_kws=dict(sharex=False, sharey=False),\n",
    "    col_wrap=3,\n",
    ")\n",
    "graph.set_axis_labels(\"Compression level\", \"Mean write time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher compression level, doesn't always mean higher read time (but maybe for some compressors? Would need more points...)\n",
    "graph = sns.relplot(\n",
    "    data=read_zarr_v2_chunks_128,\n",
    "    x=\"compression_level\",\n",
    "    y=\"stats.mean\",\n",
    "    col=\"compressor\",\n",
    "    hue=\"compressor\",\n",
    "    facet_kws=dict(sharex=False, sharey=False),\n",
    "    col_wrap=3,\n",
    ")\n",
    "graph.set_axis_labels(\"Compression level\", \"Mean read time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher write time for higher compression ratios (regardless of chunk size)\n",
    "graph = sns.relplot(\n",
    "    data=write_zarr_v2,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    col=\"chunk_size\",\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean write time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sns.relplot(\n",
    "    data=read_zarr_v2,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    col=\"chunk_size\",\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping compression level the same, larger chunks sizes compress worse (WE'D NEED TO DO AT LEAST ONE MORE CHUNK SIZE FOR THIS GRAPH TO WORK)\n",
    "# for compressor in read_zarr_v2.compressor.unique():\n",
    "#     compressor_reads = read_zarr_v2[read_zarr_v2.compressor == compressor]\n",
    "#     graph = sns.relplot(\n",
    "#         data=compressor_reads,\n",
    "#         x=\"chunk_size\",\n",
    "#         y=\"compression_ratio\",\n",
    "#         hue=\"compressor\",\n",
    "#         style=\"compressor\",\n",
    "#         col=\"compression_level\",\n",
    "#         height=4,\n",
    "#         aspect=1.2,\n",
    "#         col_wrap=3\n",
    "#     )\n",
    "#     graph.set_axis_labels(\"Chunk size\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Comparison between python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_benchmarks = read_write_benchmarks[read_write_benchmarks.group == \"write\"]\n",
    "read_benchmarks = read_write_benchmarks[read_write_benchmarks.group == \"read\"]\n",
    "write_chunks_128 = write_benchmarks[write_benchmarks.chunk_size == 128]\n",
    "read_chunks_128 = read_benchmarks[read_benchmarks.chunk_size == 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_chunks_128.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zarr python v3 and tensorstore, seem quite a bit faster than zarr python v2 for zstd/gzip\n",
    "graph = sns.relplot(\n",
    "    data=write_chunks_128,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    col=\"package\",\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean write time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zarr python v3 and tensorstore, seem quite a bit faster than zarr python v2\n",
    "for compressor in write_chunks_128.compressor.unique():\n",
    "    compressor_writes = write_chunks_128[write_chunks_128.compressor == compressor]\n",
    "    graph = sns.relplot(\n",
    "        data=compressor_writes,\n",
    "        x=\"stats.mean\",\n",
    "        y=\"compression_ratio\",\n",
    "        hue=\"package\",\n",
    "        style=\"package\",\n",
    "        size=\"compression_level\",\n",
    "        height=4,\n",
    "        aspect=1.2,\n",
    "    )\n",
    "    graph.set_axis_labels(\"Mean write time (s)\", \"Compression ratio\")\n",
    "    graph.fig.suptitle(compressor)\n",
    "    graph.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from zarr_benchmarks.create_plots import get_benchmarks_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorstore is winning for read times!\n",
    "graph = sns.relplot(\n",
    "    data=read_chunks_128,\n",
    "    x=\"stats.mean\",\n",
    "    y=\"compression_ratio\",\n",
    "    hue=\"compressor\",\n",
    "    style=\"compressor\",\n",
    "    size=\"compression_level\",\n",
    "    col=\"package\",\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n",
    "graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zarr python v3 and tensorstore, seem quite a bit faster than zarr python v2\n",
    "for compressor in read_chunks_128.compressor.unique():\n",
    "    compressor_reads = read_chunks_128[read_chunks_128.compressor == compressor]\n",
    "    graph = sns.relplot(\n",
    "        data=compressor_reads,\n",
    "        x=\"stats.mean\",\n",
    "        y=\"compression_ratio\",\n",
    "        hue=\"package\",\n",
    "        style=\"package\",\n",
    "        size=\"compression_level\",\n",
    "        height=4,\n",
    "        aspect=1.2,\n",
    "    )\n",
    "    graph.set_axis_labels(\"Mean read time (s)\", \"Compression ratio\")\n",
    "    graph.fig.suptitle(compressor)\n",
    "    graph.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heftie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
